{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f6f12fb-0ddc-4a29-81d9-8f831608e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#подгружаем библеотеки Python для работы с языко и random\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "#подгружаем библеотеки торча\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "#Используем CUDу\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b8457-d61b-4ecc-844c-c4528e1fc438",
   "metadata": {},
   "source": [
    "<h2>Будем пилить переводчик с английского на французский, в планах сделать ещё с английского на русский\n",
    "\n",
    "<h3> Делать будем по этому гайду: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html# , потому будут включены шаги, в которых нет необходимости. В переводчике с английского на русский их мы делать не будем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00ba63-a95b-4c17-a662-d93e3e64c920",
   "metadata": {},
   "source": [
    "<h3>Сперва будем использовать кодировку слов при помощи One-hot. Для этого создадим класс содержащий словари слов с соответсвтующими индеками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "633d4f91-c30f-42d1-8a3f-d82077e0bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Эти токены означают (Start-of-string) и (end-of-string) соответственно, их мы в последующем будем использовать в декодере\n",
    "#Конкретно SOS мы скармливаем декодеру в начале его работы вместе с contextом Инкодера\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {} #конкретно эта штука участвует в обработке редких слов\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "    # Дополнить список предложением\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1 #Ведём подсчёт того, сколько раз слово встретилось\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1#Ведём подсчёт того, сколько раз слово встретилось"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4acc3f-9420-43ee-acd0-cf2133617691",
   "metadata": {},
   "source": [
    "<h3> Создадим функции по предобработке данных: переведём их из Unicode в ASCII, тем самым убрав всякие страшные символы, преобразовав их к более простым, а также уменьшив объём требуемой памяти в два раза, уберём знаки препинания и верхний регистр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "efe6e2b8-3570-4d93-9eac-944b81d9dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5659c971-2ba2-4dae-951f-cf0abb5cf16f",
   "metadata": {},
   "source": [
    "<h3> определим функцию чтения файла, которая будет включать в себя обработку строк и индексирование слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7699e18c-737b-4d48-b9ef-756558d13f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):# Дэ факто lang1 и lang2 не являются необходимыми параметрами при условии что мы обрабатываем 1 файл\n",
    "    print(\"Чтение строк...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse: # на случай если мы хотим сделать не англо-французский переводчик, а французско-английский\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a694a-87e8-4476-b153-33e3993d378b",
   "metadata": {},
   "source": [
    "<h3> дабы быстро что-то обучить и пропустить часть, когда кодировка и обучение будет занимать огромное количесвто времени (а оно будт из-за one hot кодирования), мы возьмём только короткие предложение (не более 10 слов), с простыми конструкциями по типу \"я есть ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c125d4b0-1eed-4313-b054-7694f7e54ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = ( #у нас имются 2 варианта на каждый случай по причине того, что мы предврительно удалили апострофы\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110040b0-8c50-4a41-a659-e6c19b4a89d1",
   "metadata": {},
   "source": [
    "<h3> теперь поместим созданные функции в одну, которая осуществляет полную обработку входящих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "889a2d64-d42f-431d-a37c-c6a812112102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтение строк...\n",
      "Прочитано 135842 пар предложений\n",
      "Отобрано 11445 пар предложений\n",
      "Подсчёт слов...\n",
      "Число слов:\n",
      "fra 4601\n",
      "eng 2991\n",
      "\n",
      "Пример пары предложений:\n",
      " ['vous etes vraiment geniaux', 'you re really awesome']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Прочитано %s пар предложений\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Отобрано %s пар предложений\" % len(pairs))\n",
    "    print(\"Подсчёт слов...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Число слов:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(\"\\nПример пары предложений:\\n\",random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f41817-9f16-4a8c-a274-f55749f9843d",
   "metadata": {},
   "source": [
    "<h3>Настало время занятся моделью, для начала инициализируем Encoder. Будем использовать GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5c1fd11f-84ea-4409-b19e-05b93926536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)#На вход отправляется input_size слов, которые мы кодируем в вектора размера hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)# Инициализируем модель GRU (Gated Reccurent Unit, она имеет два типа воротЖ)\n",
    "                                                                   # обновления и сброса, в отличие от 3 в LSTM), которая будет принимать вектора\n",
    "                                                                    # размера hidden_size и имеет hidden_size скрытых слоёв\n",
    "                                                                    #, параметр batch_first отвечает лишь за порядок вывода\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)  # модуль зануляющий каждый элемент тензора с вероятностью dropout_p, что благотовроно влияет на обучение\n",
    "                                            # нейронной сети, путём предупреждения совместной адаптации нейрнов (Об этом стоит почитать побольше)\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))  # Прогон модели выглядит достаточно просто: имбедим(кодируем), зануляем часть,\n",
    "        output, hidden = self.gru(embedded)            # пропускаем через GRU, которая на выходе даёт нам набор закодированных предложений и\n",
    "        return output, hidden                          # конечное скрытое состояние (context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be561e7a-d55d-4b4d-ac55-1a2baf6c56ba",
   "metadata": {},
   "source": [
    "<h3>Теперь займёмся Decoder-ом. Также будем использовать GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26425f6f-3a43-4d4d-8e38-251440c4b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size) #На вход отправляется output_size слов, которые мы кодируем в вектора размера hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True) # Модель аналогичная по параметрам gru в кодировщике\n",
    "        self.out = nn.Linear(hidden_size, output_size) #линейное преобразование векторов размера hidden_size, в вектора размера output_size\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None): #на вход передаётся вызод encoder-а и его скрытое состояние (context)\n",
    "        batch_size = encoder_outputs.size(0) # определяем размер батча\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token) # создаём токен начала предложения\n",
    "                                                                                                    # для каждгого предложения в батче\n",
    "        decoder_hidden = encoder_hidden #перенимаем скрытое состояение encoder-а как первоначальное скрытое состояние decoder-a\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH): #делаем до 10 шагов decoder-а\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input // целевой тензор используется для обучения модели\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input // в противном случае используем предыдущие предсказание decoder-а\n",
    "                # как скрытое состояние\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input??????????????????\n",
    "        \n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1) #конкатенируем (склеиваем) всё в один тензор (в строках тензора хранится вероятность\n",
    "                                                            # соответсвующих слов на каждой позиции соответсвенно)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)#при помощи softmax выделяем самое вероятное слово\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "                        \n",
    "    def forward_step(self, input, hidden):      # прогон одного шага достаточно прост: имбедим, прогоняем через relu (if x<=0 =>f(x)=0 else f(x)=x),\n",
    "        output = self.embedding(input)          #далее работает GRU,возвращая свои предсказания и своё скрытое состояние,\n",
    "        output = F.relu(output)                 # предсказания преобразуем через линейную функцию до требуемого размера\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79cad6-0e95-4539-a398-9db9180a4f9c",
   "metadata": {},
   "source": [
    "<h3>Также создалим декодер с attention, для вычисления оценок внимания будет использоваться механизм Богданау, по факту являющийся моделью прямого распространения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "662ed987-31df-4a5b-a0a2-d06d1636b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size): # при инициализации мы задаём какого размера вектора состояния мы имеем\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size) # инициализируем 3 линейных преобразования, 2 из которых не меняют размерность\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size) # а третий превращает матрицу в вектор\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):# в keys попадают скрытые состояния encoder-а на каждом этапе, query - это скрытое состояние decoder-а\n",
    "                                                                                                                        # в текущий момент\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys))) # сперва строка Wa(querry) прибавляеся к каждой строке Ua(keys), далее\n",
    "                                                                # примменятеся функция тангенса и всё преобразуется в 1 вектор\n",
    "        scores = scores.squeeze(2).unsqueeze(1) #сжимаем в третьей позиции и расширяем во второй\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1) #применяем softmax к каждой строке тем самым выделяя какие состояния мы будем применять \n",
    "                                            #на разных шагах и в каком соотношении\n",
    "        context = torch.bmm(weights, keys) #производится пакетное произведение матриц в тензорах (b,a,c) @ (b,c,d) = (b,a,d)\n",
    "                                           # таким образом получаем контексты для декодера, являющиеся суммой состояний инкодера в\n",
    "                                           # разных соотношениях\n",
    "\n",
    "        return context, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b52085f-28e3-4339-8be9-a61a98c8a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1): #помимо параметров простого декодера, этот ткже принимает dropout_p\n",
    "        super(AttnDecoderRNN, self).__init__()                   # чтобы занулять чаасть элементов тензоров\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)#На вход отправляется output_size слов, которые мы кодируем в вектора размера hidden_size\n",
    "        self.attention = BahdanauAttention(hidden_size) # инициализируем наш механизм внимания\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True) #так как в гру будет поступать конкатенация вектора состояния декодера\n",
    "                                                                          #и контекста полученного при помощи attention, то входной размер в два\n",
    "                                                                           #раза больше\n",
    "        self.out = nn.Linear(hidden_size, output_size)#линейное преобразование векторов размера hidden_size, в вектора размера output_size\n",
    "        self.dropout = nn.Dropout(dropout_p) #модуль зануляющий каждый элемент тензора с вероятностью dropout_p, что благотовроно влияет на обучение\n",
    "                                            # нейронной сети, путём предупреждения совместной адаптации нейрнов\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None): #На вход берутся состояния инкодера на каждом шагу, конечное сотсояние,\n",
    "                                                                        #а также возможно, целевой тензор\n",
    "        batch_size = encoder_outputs.size(0) # определяем размер батча\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)# создаём токен начала предложения\n",
    "                                                                                                    # для каждгого предложения в батче\n",
    "        decoder_hidden = encoder_hidden #конечное скрытое состояние инкодера - начальное для декодера\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):  #делаем до 10 шагов decoder-а\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step( #на вход передаётся вход декодера, его скрытое состояние, \n",
    "                decoder_input, decoder_hidden, encoder_outputs                # все состояния инкодера\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output) #добавляем выход декодера к прочим\n",
    "            attentions.append(attn_weights) #добавим веса attention  к прочим\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing // целевой тензор используется для обучения модели(он используетяся\n",
    "                                                                  #в качесиве входного сигнала декодера вместо его предыдущего предсказания)\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input // в противном случае используем предыдущие предсказание decoder-а\n",
    "                # как скрытое состояние\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1) #производим конкатенацию полученного значения с прочими\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1) # применяем softmax для определения использованногоо слова\n",
    "        attentions = torch.cat(attentions, dim=1) #конкатенируем веса attention\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions #возвращаем полученные результаты, с состоянием декодера и весами attention\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input)) #вход декодера мы имбедим и частично зануляем\n",
    "\n",
    "        query = hidden.permute(1, 0, 2) #происходит перестановка значений скрытого состояния декодера для дальнейшего использования в attention\n",
    "        context, attn_weights = self.attention(query, encoder_outputs) #при помощи attention получаем контекст и веса\n",
    "        input_gru = torch.cat((embedded, context), dim=2) #подготавливаем конкатенацию имбеженного тензора в конкатенации с контекстом\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)# передаём конкатенацию в гру\n",
    "        output = self.out(output)# записываем результат линейного преобразования к нужному размеру\n",
    "\n",
    "        return output, hidden, attn_weights #возвращаем значения шага: результат на данном этапе(слове), состояние декодера, а также веса attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf311d8-435b-439f-96ed-72270e25a0dc",
   "metadata": {},
   "source": [
    "<h3>Для обучения модели необходимо дополнительно обработать наши данные: мы должны превратить пары предложений в соответствующие пары тензоров, состоящих из индексов наших слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04409737-f85d-4057-9706-96ff1527a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence): #функция преобразующая предложение в массив индексов слов этого предложения\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')] #используя созданный нами класс языка\n",
    "\n",
    "def tensorFromSentence(lang, sentence): #функция преобразующая предложение в тензор, на вход принимает язык и предложение\n",
    "    indexes = indexesFromSentence(lang, sentence) #сперва преобразуем в индексы\n",
    "    indexes.append(EOS_token) # добавляем в конце маркер конца предложения\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1) #возвращает тензор, где все индексы записаны в 1 колонку\n",
    "\n",
    "def tensorsFromPair(pair): #создаёт пару соответствующих друг другу тензоров\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0]) #просто пр именяем преобразование к обоим предложениям в контексте их яхыков\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size): #функция создания datalouder  для двух конкретных языков, английского и французского, на вход принимает размер батча\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True) #предобрабатываем наши строки, создаём для них классы языков\n",
    "\n",
    "    n = len(pairs) #число пар\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32) #создаём обучающие тензоры имеющие в строках списки индексов слов\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32) #пока что они заполены нолями\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs): #через цикл перебираем все пары\n",
    "        inp_ids = indexesFromSentence(input_lang, inp) #из предложений получаем списки индексов\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt) \n",
    "        inp_ids.append(EOS_token)#добавляем к ним токен конца предложения\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids#Заполняем обучающие тензоры полученными индексами\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device), \n",
    "                               torch.LongTensor(target_ids).to(device)) #преобразуем тензоры в датасет, где эти тензоры будут являтся столбцами датасета\n",
    "\n",
    "    train_sampler = RandomSampler(train_data) #Если я праавильно понял, то мы рандомно дробим наш датасет и согласно этомк разбиению формируем\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) #наш Datsloader, специальный класс для итерации по \n",
    "                                                                                            # датасету\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd63d3-6b9e-496e-aca8-4ce228be67cf",
   "metadata": {},
   "source": [
    "<h3> Далее определяем функцию обучения (1 эпоху)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1fedbd4-fd5e-4568-8d0f-3b9fd8b77cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, #на вход передаётся наш dataloader. encoder, decoder, их оптимизаторы\n",
    "          decoder_optimizer, criterion):                          # а также функция оценки качества (ошибки), которую мы будем минимизировать\n",
    "\n",
    "    total_loss = 0 \n",
    "    for data in dataloader: # производим итерацию по батчам наших данных\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad() #обнуляем градиенты, чтобы они не складывались на каждой итерации\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor) #прогоняем батч через инкодер и декодер\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)), #вычисляем нашу ошибку\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward() #проводим обратное распространение, вычисляютя градиенты\n",
    "\n",
    "        encoder_optimizer.step() #корректируем веса нейронок использую аптимизаторы\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() #вычисляем ошибку по эпохе (сумма ошибок)\n",
    "\n",
    "    return total_loss / len(dataloader) #возвращаем среднюю ошибку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a307b-9846-43a7-bfa2-197dfca87d8e",
   "metadata": {},
   "source": [
    "<h3> Создадим вспомогательную функцию для отображения времени и прогресса обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f66975ba-8dd3-4916-9cd5-ce74889f5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87570a9-c600-438d-bc10-ebcd0e71c0d4",
   "metadata": {},
   "source": [
    " В целом процесс обучения можно представит в следующих этапах <br>\n",
    "-запуск таймера<br>\n",
    "-Инициализация оптимизаторов и критерия<br>\n",
    "-Создание набора обучающих пар<br>\n",
    "-Запуск пустого массива потерь для построения графа в дальнейшем</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c18b5-c990-48aa-9cc0-16053f3b4639",
   "metadata": {},
   "source": [
    "Затем мы вызываем много раз train_epoch и печатаем прогресс (% примеров, время на данный момент, расчетное время) и средние потери"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0a8b8be-15a2-44c2-95c5-d3d07b1916de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, #передаём наши данные, инкодер, декодер, число эпох\n",
    "               print_every=100, plot_every=100):          #learning_rate(как сильно мы будем изменять веса каждый раз), а также как часто\n",
    "                                                        #выводить промежуточные результаты\n",
    "    start = time.time() #стартуем таймер\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  #задаём внутренние переменные\n",
    "    plot_loss_total = 0  \n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate) #инициализируем оптимизаторы для наших нейронок, передаём в них \n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate) # learning_rate\n",
    "    criterion = nn.NLLLoss() # задаём функцию потерь как для классификации (с этим тоже разобраться стоит подробнее)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1): #по количеству эпох итерируем\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) #тренируем и вычисляем ошибку\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss#складываем ошибки\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),              #выводим среднюю ошибку на данном этапе\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg) #складываем для последующего вывода\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses) #показываем график ошибок"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca1d04-e50a-4cc8-832f-3f51d2c671a6",
   "metadata": {},
   "source": [
    "<h3> Определим функцию вывода ошибок при помощи matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "244443f3-b2f3-4e01-ac11-0983153bab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccf262f-34f6-4ab6-b285-f5f5fe1bd5c6",
   "metadata": {},
   "source": [
    "<h3>Создадим функцию оценки, по большому счёту она похожа на функцию обучения, но использует состояния декодера вместо целевого тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b5aade71-9f96-46f8-85a3-a19b883b37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang): #на вход передаём наши инкодер с декодером, предложение и языки\n",
    "    with torch.no_grad(): #отключаем расчёт градиента за ненадобностью при оценке\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence) #преобразуем предложение\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor) # прогоняем его через инкодер и декодер\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)# получаем по 1 одному наибольшему элементу по строкам нашего ответа (по факту самые вероятные слова)\n",
    "        decoded_ids = topi.squeeze() #сворачиваем в 1 строку\n",
    "\n",
    "        decoded_words = [] #массив с переводом\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>') #через цикл дополняем наши слова перевода в массив, до того как встретится токен окончания предложения\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn #возвращаем перевод и состояния attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c125b93f-81cd-472e-9032-f143f4ed22b3",
   "metadata": {},
   "source": [
    "<h3> создадим функцию для оценки заданного числа предложений, которые мы сможем посмотреть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f667b88e-4675-4948-9345-f4cd0e451ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)#рандомно выбираем пару предложений\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang) #производим оценку-перевод\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db13b6-c722-4f73-8122-548372fc8149",
   "metadata": {},
   "source": [
    "<h3> Теперь имея все вспомгательные функции можно начть процесс обучения и оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2e89c505-81d3-4f88-ad42-3cd13df530f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтение строк...\n",
      "Прочитано 135842 пар предложений\n",
      "Отобрано 11445 пар предложений\n",
      "Подсчёт слов...\n",
      "Число слов:\n",
      "fra 4601\n",
      "eng 2991\n",
      "0m 49s (- 12m 17s) (5 6%) 1.5264\n",
      "1m 32s (- 10m 50s) (10 12%) 0.6639\n",
      "2m 17s (- 9m 55s) (15 18%) 0.3431\n",
      "3m 1s (- 9m 5s) (20 25%) 0.1933\n",
      "3m 46s (- 8m 18s) (25 31%) 0.1227\n",
      "4m 31s (- 7m 31s) (30 37%) 0.0872\n",
      "5m 15s (- 6m 45s) (35 43%) 0.0671\n",
      "6m 0s (- 6m 0s) (40 50%) 0.0561\n",
      "6m 44s (- 5m 14s) (45 56%) 0.0478\n",
      "7m 29s (- 4m 29s) (50 62%) 0.0425\n",
      "8m 14s (- 3m 44s) (55 68%) 0.0396\n",
      "8m 58s (- 2m 59s) (60 75%) 0.0360\n",
      "9m 43s (- 2m 14s) (65 81%) 0.0347\n",
      "10m 27s (- 1m 29s) (70 87%) 0.0326\n",
      "11m 12s (- 0m 44s) (75 93%) 0.0317\n",
      "11m 56s (- 0m 0s) (80 100%) 0.0298\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32 #установим 256 скрытых слоёв и размер батча в 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size) #получим данные\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device) #инициализируем наши нейронки\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)# начнём обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f617201b-bbd5-4b87-b51b-040f9657d213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> j attends un client aujourd hui\n",
      "= i m expecting a customer today\n",
      "< i m expecting a customer today <EOS>\n",
      "\n",
      "> elles sont nerveuses\n",
      "= they re jittery\n",
      "< they re jittery <EOS>\n",
      "\n",
      "> ils sont capables de chanter\n",
      "= they re able to sing\n",
      "< they re able to sing <EOS>\n",
      "\n",
      "> je suis vraiment prudente\n",
      "= i m real careful\n",
      "< i m real careful but he s careful <EOS>\n",
      "\n",
      "> il est different de ce qu il etait avant\n",
      "= he s different from before\n",
      "< he s different from before <EOS>\n",
      "\n",
      "> nous allons faire ce que nous pouvons\n",
      "= we re going to do everything we can\n",
      "< we re going to do everything we can <EOS>\n",
      "\n",
      "> vous etes fort attirante\n",
      "= you re very attractive\n",
      "< you re very attractive <EOS>\n",
      "\n",
      "> tu es fascinante\n",
      "= you re fascinating\n",
      "< you re fascinating <EOS>\n",
      "\n",
      "> tu es fort sage\n",
      "= you re very wise\n",
      "< you re very wise <EOS>\n",
      "\n",
      "> ils sont mes amis\n",
      "= they are my friends\n",
      "< they are my friends <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval() #переходим в ознакомительный режим\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder) # проводим оценку получившегося"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89893f70-77b3-4feb-8c79-130d31977aab",
   "metadata": {},
   "source": [
    "<h3> В целом похоже на правду. Обучение можно считать успешным"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521c440-4bf0-4cbf-a0ae-bcbfe96009ed",
   "metadata": {},
   "source": [
    "<h3> Можно визуализирвать результаты attention, чтобы просмотреть какие именно состояния выбираются attention и влияют на предсказания декодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a675d171-3131-4675-a4cd-089ec5db6f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = il n est pas aussi grand que son pere\n",
      "output = he is not as tall as his father <EOS>\n",
      "input = je suis trop fatigue pour conduire\n",
      "output = i m too tired to drive <EOS>\n",
      "input = je suis desole si c est une question idiote\n",
      "output = i m sorry if this is a stupid question <EOS>\n",
      "input = je suis reellement fiere de vous\n",
      "output = i m really proud of you <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ov00v\\AppData\\Local\\Temp\\ipykernel_11512\\1152658574.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
    "\n",
    "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
    "\n",
    "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
    "\n",
    "evaluateAndShowAttention('je suis reellement fiere de vous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf8e18-d8c8-4ada-90d6-e7447d6770c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde2e54-3ed1-40b7-81f5-9559500a4bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f88c0-7322-42ef-8509-c8ecfcad2cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a09900-d337-4a84-be40-469ddf814577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b27f8-ac9f-44c4-a424-70f12e1fb2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8bfd76-42fd-47c9-a3bd-2255147a7029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
