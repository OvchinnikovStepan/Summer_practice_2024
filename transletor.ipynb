{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6f12fb-0ddc-4a29-81d9-8f831608e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#подгружаем библеотеки Python для работы с языко и random\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "#подгружаем библеотеки торча\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "#Используем CUDу\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "104077aa-5734-4b54-ae1a-62ae543d56bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: torch>=2.3.0 in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from torchtext) (2.3.1+cu121)\n",
      "Requirement already satisfied: tqdm in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from torchtext) (4.66.4)\n",
      "Requirement already satisfied: requests in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from torchtext) (2.32.3)\n",
      "Requirement already satisfied: numpy in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from torchtext) (1.26.3)\n",
      "Requirement already satisfied: networkx in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from torch>=2.3.0->torchtext) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from torch>=2.3.0->torchtext) (4.9.0)\n",
      "Requirement already satisfied: fsspec in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from torch>=2.3.0->torchtext) (2024.2.0)\n",
      "Requirement already satisfied: sympy in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from torch>=2.3.0->torchtext) (1.12)\n",
      "Requirement already satisfied: filelock in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from torch>=2.3.0->torchtext) (3.13.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from torch>=2.3.0->torchtext) (2021.4.0)\n",
      "Requirement already satisfied: jinja2 in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from torch>=2.3.0->torchtext) (3.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from requests->torchtext) (2024.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from requests->torchtext) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from requests->torchtext) (2.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from requests->torchtext) (3.7)\n",
      "Requirement already satisfied: colorama in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from tqdm->torchtext) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.3.0->torchtext) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.3.0->torchtext) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\my_code\\summer_practice2024\\sec2sec\\lib\\site-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b8457-d61b-4ecc-844c-c4528e1fc438",
   "metadata": {},
   "source": [
    "<h2>Будем пилить переводчик с английского на французский, в планах сделать ещё с английского на русский\n",
    "\n",
    "<h3> Делать будем по этому гайду: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html# , потому будут включены шаги, в которых нет необходимости. В переводчике с английского на русский их мы делать не будем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00ba63-a95b-4c17-a662-d93e3e64c920",
   "metadata": {},
   "source": [
    "<h3>Сперва будем использовать кодировку слов при помощи One-hot. Для этого создадим класс содержащий словари слов с соответсвтующими индеками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633d4f91-c30f-42d1-8a3f-d82077e0bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Эти токены означают (Start-of-string) и (end-of-string) соответственно, их мы в последующем будем использовать в декодере\n",
    "#Конкретно SOS мы скармливаем декодеру в начале его работы вместе с contextом Инкодера\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang: #классы представляют собой языки с числом тех или иных слов и их индексами\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {} \n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "    # Дополнить список предложением\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1 #Ведём подсчёт того, сколько раз слово встретилось\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1#Ведём подсчёт того, сколько раз слово встретилось"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4acc3f-9420-43ee-acd0-cf2133617691",
   "metadata": {},
   "source": [
    "<h3> Создадим функции по предобработке данных: переведём их из Unicode в ASCII, тем самым убрав всякие страшные символы, преобразовав их к более простым, а также уменьшив объём требуемой памяти в два раза, уберём знаки препинания и верхний регистр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe6e2b8-3570-4d93-9eac-944b81d9dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5659c971-2ba2-4dae-951f-cf0abb5cf16f",
   "metadata": {},
   "source": [
    "<h3> определим функцию чтения файла, которая будет включать в себя обработку строк и индексирование слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7699e18c-737b-4d48-b9ef-756558d13f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):# Дэ факто lang1 и lang2 не являются необходимыми параметрами при условии что мы обрабатываем 1 файл\n",
    "    print(\"Чтение строк...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse: # на случай если мы хотим сделать не англо-французский переводчик, а французско-английский\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a694a-87e8-4476-b153-33e3993d378b",
   "metadata": {},
   "source": [
    "<h3> дабы быстро что-то обучить, мы возьмём только короткие предложение (не более 10 слов), с простыми конструкциями по типу \"я есть ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c125d4b0-1eed-4313-b054-7694f7e54ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100\n",
    "\n",
    "eng_prefixes = ( #у нас имются 2 варианта на каждый случай по причине того, что мы предврительно удалили апострофы\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110040b0-8c50-4a41-a659-e6c19b4a89d1",
   "metadata": {},
   "source": [
    "<h3> теперь поместим созданные функции в одну, которая осуществляет полную обработку входящих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "889a2d64-d42f-431d-a37c-c6a812112102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтение строк...\n",
      "Прочитано 135842 пар предложений\n",
      "Отобрано 13078 пар предложений\n",
      "Подсчёт слов...\n",
      "Число слов:\n",
      "fra 5173\n",
      "eng 3388\n",
      "\n",
      "Пример пары предложений:\n",
      " ['vous etes soucieuse n est ce pas ?', 'you re worried aren t you ?']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Прочитано %s пар предложений\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Отобрано %s пар предложений\" % len(pairs))\n",
    "    print(\"Подсчёт слов...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Число слов:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(\"\\nПример пары предложений:\\n\",random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f41817-9f16-4a8c-a274-f55749f9843d",
   "metadata": {},
   "source": [
    "<h3>Настало время занятся моделью, для начала инициализируем Encoder. Будем использовать GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c1fd11f-84ea-4409-b19e-05b93926536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)#На вход отправляется вектора размера input_size, которые мы кодируем в вектора размера hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)# Инициализируем модель GRU (Gated Reccurent Unit, она имеет два типа воротЖ)\n",
    "                                                                   # обновления и сброса, в отличие от 3 в LSTM), которая будет принимать вектора\n",
    "                                                                    # размера hidden_size и имеет hidden_size скрытых слоёв\n",
    "                                                                    #, параметр batch_first отвечает лишь за порядок вывода\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)  # модуль зануляющий каждый элемент тензора с вероятностью dropout_p, что благотовроно влияет на обучение\n",
    "                                            # нейронной сети, путём предупреждения совместной адаптации нейрнов (Об этом стоит почитать побольше)\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))  # Прогон модели выглядит достаточно просто: имбедим(кодируем), зануляем часть,\n",
    "        output, hidden = self.gru(embedded)            # пропускаем через GRU, которая на выходе даёт нам набор закодированных предложений и\n",
    "        return output, hidden                          # конечное скрытое состояние (context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be561e7a-d55d-4b4d-ac55-1a2baf6c56ba",
   "metadata": {},
   "source": [
    "<h3>Теперь займёмся Decoder-ом. Также будем использовать GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26425f6f-3a43-4d4d-8e38-251440c4b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size) #На вход отправляется output_size слов, которые мы кодируем в вектора размера hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True) # Модель аналогичная по параметрам gru в кодировщике\n",
    "        self.out = nn.Linear(hidden_size, output_size) #линейное преобразование векторов размера hidden_size, в вектора размера output_size\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None): #на вход передаётся вызод encoder-а и его скрытое состояние (context)\n",
    "        batch_size = encoder_outputs.size(0) # определяем размер батча\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token) # создаём токен начала предложения\n",
    "                                                                                                    # для каждгого предложения в батче\n",
    "        decoder_hidden = encoder_hidden #перенимаем скрытое состояение encoder-а как первоначальное скрытое состояние decoder-a\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH): #делаем до 10 шагов decoder-а\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input // целевой тензор используется для обучения модели\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input // в противном случае используем предыдущие предсказание decoder-а\n",
    "                # как скрытое состояние\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input??????????????????\n",
    "        \n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1) #конкатенируем (склеиваем) всё в один тензор (в строках тензора хранится вероятность\n",
    "                                                            # соответсвующих слов на каждой позиции соответсвенно)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)#при помощи softmax выделяем самое вероятное слово\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "                        \n",
    "    def forward_step(self, input, hidden):      # прогон одного шага достаточно прост: имбедим, прогоняем через relu (if x<=0 =>f(x)=0 else f(x)=x),\n",
    "        output = self.embedding(input)          #далее работает GRU,возвращая свои предсказания и своё скрытое состояние,\n",
    "        output = F.relu(output)                 # предсказания преобразуем через линейную функцию до требуемого размера\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79cad6-0e95-4539-a398-9db9180a4f9c",
   "metadata": {},
   "source": [
    "<h3>Также создадим декодер с attention, для вычисления оценок внимания будет использоваться механизм Богданау, по факту являющийся моделью прямого распространения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "662ed987-31df-4a5b-a0a2-d06d1636b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size): # при инициализации мы задаём какого размера вектора состояния мы имеем\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size) # инициализируем 3 линейных преобразования, 2 из которых не меняют размерность\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size) # а третий превращает матрицу в вектор\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):# в keys попадают скрытые состояния encoder-а на каждом этапе, query - это скрытое состояние decoder-а\n",
    "                                                                                                                        # в текущий момент\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys))) # сперва строка Wa(querry) прибавляеся к каждой строке Ua(keys), далее\n",
    "                                                                # примменятеся функция тангенса и всё преобразуется в 1 вектор\n",
    "        scores = scores.squeeze(2).unsqueeze(1) #сжимаем в третьей позиции и расширяем во второй\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1) #применяем softmax к каждой строке тем самым выделяя какие состояния мы будем применять \n",
    "                                            #на разных шагах и в каком соотношении\n",
    "        context = torch.bmm(weights, keys) #производится пакетное произведение матриц в тензорах (b,a,c) @ (b,c,d) = (b,a,d)\n",
    "                                           # таким образом получаем контексты для декодера, являющиеся суммой состояний инкодера в\n",
    "                                           # разных соотношениях\n",
    "\n",
    "        return context, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b52085f-28e3-4339-8be9-a61a98c8a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1): #помимо параметров простого декодера, этот ткже принимает dropout_p\n",
    "        super(AttnDecoderRNN, self).__init__()                   # чтобы занулять чаасть элементов тензоров\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)#На вход отправляется output_size слов, которые мы кодируем в вектора размера hidden_size\n",
    "        self.attention = BahdanauAttention(hidden_size) # инициализируем наш механизм внимания\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True) #так как в гру будет поступать конкатенация вектора состояния декодера\n",
    "                                                                          #и контекста полученного при помощи attention, то входной размер в два\n",
    "                                                                           #раза больше\n",
    "        self.out = nn.Linear(hidden_size, output_size)#линейное преобразование векторов размера hidden_size, в вектора размера output_size\n",
    "        self.dropout = nn.Dropout(dropout_p) #модуль зануляющий каждый элемент тензора с вероятностью dropout_p, что благотовроно влияет на обучение\n",
    "                                            # нейронной сети, путём предупреждения совместной адаптации нейрнов\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None): #На вход берутся состояния инкодера на каждом шагу, конечное сотсояние,\n",
    "                                                                        #а также возможно, целевой тензор\n",
    "        batch_size = encoder_outputs.size(0) # определяем размер батча\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)# создаём токен начала предложения\n",
    "                                                                                                    # для каждгого предложения в батче\n",
    "        decoder_hidden = encoder_hidden #конечное скрытое состояние инкодера - начальное для декодера\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):  #делаем до 10 шагов decoder-а\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step( #на вход передаётся вход декодера, его скрытое состояние, \n",
    "                decoder_input, decoder_hidden, encoder_outputs                # все состояния инкодера\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output) #добавляем выход декодера к прочим\n",
    "            attentions.append(attn_weights) #добавим веса attention  к прочим\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing // целевой тензор используется для обучения модели(он используетяся\n",
    "                                                                  #в качесиве входного сигнала декодера вместо его предыдущего предсказания)\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input // в противном случае используем предыдущие предсказание decoder-а\n",
    "                # как скрытое состояние\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1) #производим конкатенацию полученного значения с прочими\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1) # применяем softmax для определения использованногоо слова\n",
    "        attentions = torch.cat(attentions, dim=1) #конкатенируем веса attention\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions #возвращаем полученные результаты, с состоянием декодера и весами attention\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input)) #вход декодера мы имбедим и частично зануляем\n",
    "\n",
    "        query = hidden.permute(1, 0, 2) #происходит перестановка значений скрытого состояния декодера для дальнейшего использования в attention\n",
    "        context, attn_weights = self.attention(query, encoder_outputs) #при помощи attention получаем контекст и веса\n",
    "        input_gru = torch.cat((embedded, context), dim=2) #подготавливаем конкатенацию имбеженного тензора в конкатенации с контекстом\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)# передаём конкатенацию в гру\n",
    "        output = self.out(output)# записываем результат линейного преобразования к нужному размеру\n",
    "\n",
    "        return output, hidden, attn_weights #возвращаем значения шага: результат на данном этапе(слове), состояние декодера, а также веса attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf311d8-435b-439f-96ed-72270e25a0dc",
   "metadata": {},
   "source": [
    "<h3>Для обучения модели необходимо дополнительно обработать наши данные: мы должны превратить пары предложений в соответствующие пары тензоров, состоящих из индексов наших слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02f6108d-01c2-4e2c-8a0e-0e7203204f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04409737-f85d-4057-9706-96ff1527a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence): #функция преобразующая предложение в массив индексов слов этого предложения\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')] #используя созданный нами класс языка\n",
    "\n",
    "#def SentenceFromIndexes(lang,indexis):\n",
    "#    return [lang.index2word[index] for index in indexis]\n",
    " #   \n",
    "#def SentenciesFromIndexies(lang,indexies):\n",
    "#    return [SentenceFromIndexes(lang, index) for index in indexis]\n",
    "\n",
    "def tensorFromSentence(lang, sentence): #функция преобразующая предложение в тензор, на вход принимает язык и предложение\n",
    "    indexes = indexesFromSentence(lang, sentence) #сперва преобразуем в индексы\n",
    "    indexes.append(EOS_token) # добавляем в конце маркер конца предложения\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1) #возвращает тензор, где все индексы записаны в 1 колонку\n",
    "\n",
    "def tensorsFromPair(pair): #создаёт пару соответствующих друг другу тензоров\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0]) #просто пр именяем преобразование к обоим предложениям в контексте их яхыков\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size): #функция создания datalouder  для двух конкретных языков, английского и французского, на вход принимает размер батча\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True) #предобрабатываем наши строки, создаём для них классы языков\n",
    "\n",
    "    n = len(pairs) #число пар\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32) #создаём обучающие тензоры имеющие в строках списки индексов слов\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32) #пока что они заполены нолями\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs): #через цикл перебираем все пары\n",
    "        inp_ids = indexesFromSentence(input_lang, inp) #из предложений получаем списки индексов\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt) \n",
    "        inp_ids.append(EOS_token)#добавляем к ним токен конца предложения\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids#Заполняем обучающие тензоры полученными индексами\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    input_train, input_eval, target_train, target_eval = train_test_split(input_ids, target_ids, test_size=0.2, random_state=42)#разбиваем данные на train\n",
    "    input_val, input_test, target_val, target_test = train_test_split(input_ids, target_ids, test_size=0.5, random_state=42)# test, val\n",
    "    \n",
    "    train_data = TensorDataset(torch.LongTensor(input_train).to(device), \n",
    "                               torch.LongTensor(target_train).to(device)) #преобразуем тензоры в датасет, где эти тензоры будут являтся столбцами датасета\n",
    "\n",
    "    train_sampler = RandomSampler(train_data) #Если я праавильно понял, то мы рандомно дробим наш датасет и согласно этомк разбиению формируем\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) #наш Datsloader, специальный класс для итерации по \n",
    "                                                                                            # датасету\n",
    "\n",
    "    val_data = TensorDataset(torch.LongTensor(input_val).to(device), \n",
    "                               torch.LongTensor(target_val).to(device)) \n",
    "\n",
    "    val_sampler = RandomSampler(train_data)                                                   #по отношению к оценочным и тестовым данным действум тем\n",
    "    val_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)     #же образом\n",
    "    \n",
    "    test_data = TensorDataset(torch.LongTensor(input_test).to(device), \n",
    "                               torch.LongTensor(target_test).to(device)) \n",
    "\n",
    "    test_sampler = RandomSampler(train_data)\n",
    "    test_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "                                                                                           \n",
    "    return input_lang, output_lang, train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd63d3-6b9e-496e-aca8-4ce228be67cf",
   "metadata": {},
   "source": [
    "<h3> Далее определяем функцию обучения (1 эпоху)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1fedbd4-fd5e-4568-8d0f-3b9fd8b77cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, #на вход передаётся наш dataloader. encoder, decoder, их оптимизаторы\n",
    "          decoder_optimizer, criterion):                          # а также функция оценки качества (ошибки), которую мы будем минимизировать\n",
    "    encoder.train()\n",
    "    decoder.train()#подрубаем режим тренировки\n",
    "    total_loss = 0 \n",
    "    for data in dataloader: # производим итерацию по батчам наших данных\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad() #обнуляем градиенты, чтобы они не складывались на каждой итерации\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor) #прогоняем батч через инкодер и декодер\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)), #вычисляем нашу ошибку\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward() #проводим обратное распространение, вычисляютя градиенты\n",
    "\n",
    "        encoder_optimizer.step() #корректируем веса нейронок использую аптимизаторы\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() #вычисляем ошибку по эпохе (сумма ошибок)\n",
    "\n",
    "    return total_loss / len(dataloader) #возвращаем среднюю ошибку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d036751e-5d2b-470b-98cd-3baf4f2ec621",
   "metadata": {},
   "source": [
    "<h3> Определим функцию оценки промежуточных результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48012694-f558-4b69-8c20-d3e96ed694e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(dataloader, encoder, decoder, #на вход передаётся наш dataloader. encoder, decoder\n",
    "           criterion):                          # а также функция оценки качества (ошибки), которую мы будем минимизировать\n",
    "    encoder.eval()\n",
    "    decoder.eval() #подрубаем режим оценки\n",
    "    val_loss = 0 \n",
    "    for data in dataloader: # производим итерацию по батчам наших данных\n",
    "        \n",
    "        input_tensor,  target_tensor = data\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor) #прогоняем батч через инкодер и декодер\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)), #вычисляем нашу ошибку\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        val_loss += loss.item() #вычисляем ошибку по эпохе (сумма ошибок)\n",
    "\n",
    "    return val_loss / len(dataloader) #возвращаем среднюю ошибку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a307b-9846-43a7-bfa2-197dfca87d8e",
   "metadata": {},
   "source": [
    "<h3> Создадим вспомогательную функцию для отображения времени и прогресса обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f66975ba-8dd3-4916-9cd5-ce74889f5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87570a9-c600-438d-bc10-ebcd0e71c0d4",
   "metadata": {},
   "source": [
    " В целом процесс обучения можно представит в следующих этапах <br>\n",
    "-запуск таймера<br>\n",
    "-Инициализация оптимизаторов и критерия<br>\n",
    "-Создание набора обучающих пар<br>\n",
    "-Запуск пустого массива потерь для построения графа в дальнейшем</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c18b5-c990-48aa-9cc0-16053f3b4639",
   "metadata": {},
   "source": [
    "Затем мы вызываем много раз train_epoch и печатаем прогресс (% примеров, время на данный момент, расчетное время) и средние потери"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0a8b8be-15a2-44c2-95c5-d3d07b1916de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader,val_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, #передаём наши данные, инкодер, декодер, число эпох\n",
    "               print_every=100, plot_every=100):          #learning_rate(как сильно мы будем изменять веса каждый раз), а также как часто\n",
    "                                                        #выводить промежуточные результаты\n",
    "    start = time.time() #стартуем таймер\n",
    "    plot_losses = []\n",
    "    plot_val_losses = []\n",
    "    print_loss_total = 0  #задаём внутренние переменные\n",
    "    plot_loss_total = 0  \n",
    "    print_val_loss_total =0\n",
    "    plot_val_loss_total =0\n",
    "    val_loss_previous=math.inf\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate) #инициализируем оптимизаторы для наших нейронок, передаём в них \n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate) # learning_rate\n",
    "    criterion = nn.NLLLoss() # задаём функцию потерь как для классификации (с этим тоже разобраться стоит подробнее)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1): #по количеству эпох итерируем\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) #тренируем и вычисляем ошибку\n",
    "        val_loss=val_epoch(val_dataloader,encoder,decoder,criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss#складываем ошибки\n",
    "        print_val_loss_total += val_loss\n",
    "        plot_val_loss_total += val_loss#складываем ошибки\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print_val_loss_avg = print_val_loss_total / print_every\n",
    "            \n",
    "            print('%s (%d %d%%) train_losses=%.4f val_losses=%.4f' % (timeSince(start, epoch / n_epochs),              #выводим среднюю ошибку на данном этапе\n",
    "                                        epoch, epoch / n_epochs * 100,print_loss_avg,print_val_loss_avg))\n",
    "            if (val_loss_previous<=print_val_loss_total):\n",
    "                print(\"Training was interupted due to start of overfitting\")\n",
    "                break\n",
    "            val_loss_previous=print_val_loss_total\n",
    "            print_val_loss_total = 0\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg) #складываем для последующего вывода\n",
    "            plot_loss_total = 0\n",
    "            plot_val_loss_avg = plot_val_loss_total / plot_every\n",
    "            plot_val_losses.append(plot_val_loss_avg) #складываем для последующего вывода\n",
    "            plot_val_loss_total = 0\n",
    "    print(\"Training finishid.\")\n",
    "    showPlot(plot_losses) #показываем график ошибок\n",
    "    showPlot(plot_val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca1d04-e50a-4cc8-832f-3f51d2c671a6",
   "metadata": {},
   "source": [
    "<h3> Определим функцию вывода ошибок при помощи matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "244443f3-b2f3-4e01-ac11-0983153bab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "plt.close('all')\n",
    "matplotlib.use('TkAgg')\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccf262f-34f6-4ab6-b285-f5f5fe1bd5c6",
   "metadata": {},
   "source": [
    "<h3>Создадим функцию оценки, по большому счёту она похожа на функцию обучения, но использует состояния декодера вместо целевого тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5aade71-9f96-46f8-85a3-a19b883b37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang): #на вход передаём наши инкодер с декодером, предложение и языки\n",
    "    with torch.no_grad(): #отключаем расчёт градиента за ненадобностью при оценке\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence) #преобразуем предложение\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor) # прогоняем его через инкодер и декодер\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)# получаем по 1 одному наибольшему элементу по строкам нашего ответа (по факту самые вероятные слова)\n",
    "        decoded_ids = topi.squeeze() #сворачиваем в 1 строку\n",
    "\n",
    "        decoded_words = [] #массив с переводом\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>') #через цикл дополняем наши слова перевода в массив, до того как встретится токен окончания предложения\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn #возвращаем перевод и состояния attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c125b93f-81cd-472e-9032-f143f4ed22b3",
   "metadata": {},
   "source": [
    "<h3> создадим функцию для оценки заданного числа предложений, которые мы сможем посмотреть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f667b88e-4675-4948-9345-f4cd0e451ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)#рандомно выбираем пару предложений\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang) #производим оценку-перевод\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db13b6-c722-4f73-8122-548372fc8149",
   "metadata": {},
   "source": [
    "<h3> Теперь имея все вспомгательные функции можно начть процесс обучения и оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e89c505-81d3-4f88-ad42-3cd13df530f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтение строк...\n",
      "Прочитано 135842 пар предложений\n",
      "Отобрано 13078 пар предложений\n",
      "Подсчёт слов...\n",
      "Число слов:\n",
      "fra 5173\n",
      "eng 3388\n",
      "7m 1s (- 133m 21s) (4 5%) train_losses=0.2829 val_losses=0.4005\n",
      "14m 23s (- 129m 33s) (8 10%) train_losses=0.1472 val_losses=0.3294\n",
      "21m 27s (- 121m 38s) (12 15%) train_losses=0.1030 val_losses=0.2714\n",
      "28m 30s (- 114m 1s) (16 20%) train_losses=0.0705 val_losses=0.2052\n",
      "35m 48s (- 107m 25s) (20 25%) train_losses=0.0478 val_losses=0.1477\n",
      "42m 36s (- 99m 26s) (24 30%) train_losses=0.0326 val_losses=0.1034\n",
      "49m 45s (- 92m 25s) (28 35%) train_losses=0.0226 val_losses=0.0692\n",
      "57m 0s (- 85m 30s) (32 40%) train_losses=0.0162 val_losses=0.0483\n",
      "63m 56s (- 78m 9s) (36 45%) train_losses=0.0121 val_losses=0.0332\n",
      "71m 30s (- 71m 30s) (40 50%) train_losses=0.0095 val_losses=0.0239\n",
      "78m 30s (- 64m 13s) (44 55%) train_losses=0.0077 val_losses=0.0196\n",
      "86m 4s (- 57m 23s) (48 60%) train_losses=0.0065 val_losses=0.0165\n",
      "92m 55s (- 50m 1s) (52 65%) train_losses=0.0056 val_losses=0.0139\n",
      "99m 45s (- 42m 45s) (56 70%) train_losses=0.0050 val_losses=0.0133\n",
      "139m 49s (- 46m 36s) (60 75%) train_losses=0.0046 val_losses=0.0126\n",
      "146m 25s (- 36m 36s) (64 80%) train_losses=0.0043 val_losses=0.0120\n",
      "154m 0s (- 27m 10s) (68 85%) train_losses=0.0039 val_losses=0.0121\n",
      "Training was interupted due to start of overfitting\n",
      "Training finishid.\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32 #установим 256 скрытых слоёв и размер батча в 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader,val_dataloader,test_dataloader = get_dataloader(batch_size) #получим данные\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device) #инициализируем наши нейронки\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader,val_dataloader, encoder, decoder, 80, print_every=4, plot_every=5)# начнём обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012a3fc-cba1-48bd-99fc-9f6f2ad9a590",
   "metadata": {},
   "source": [
    "<h3> Произведём оценку модели на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1b30508-8bab-44b5-8dda-2b1d16c6184b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01199440084399929"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "val_epoch(test_dataloader, encoder, decoder, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f6e5a97-7d8d-4d34-98e2-514a33c024c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.data.metrics as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4df4f32f-ad89-42c6-8550-224dcb7ed719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_evaluate(test_dataloader,encoder, decoder, input_lang, output_lang): #на вход передаём наши инкодер с декодером, предложение и языки\n",
    "    with torch.no_grad():\n",
    "        total_bleu_score=0\n",
    "        for data in test_dataloader:\n",
    "            F_indexies,Ideal_translation=data\n",
    "           \n",
    "            encoder_outputs, encoder_hidden = encoder(F_indexies) # прогоняем его через инкодер и декодер\n",
    "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "            _, topi = decoder_outputs.topk(1)# получаем по 1 одному наибольшему элементу по строкам нашего ответа (по факту самые вероятные слова)\n",
    "            S_indexies = topi.squeeze() #сворачиваем в 1 строку\n",
    "          #  print(Ideal_translation)\n",
    "            decoded_words = [[] for i in range(len(S_indexies))] #массив с переводом\n",
    "            #print(S_indexies.shape)\n",
    "            for i in range(len(S_indexies)):\n",
    "                for idx in S_indexies[i]:\n",
    "                    if idx.item() == EOS_token:\n",
    "                        break\n",
    "                    decoded_words[i].append(output_lang.index2word[idx.item()])\n",
    "            translation=[[[]] for i in range(len(Ideal_translation))]\n",
    "           # print( Ideal_translation.shape)\n",
    "            for i in range(len(Ideal_translation)):\n",
    "                for idx in Ideal_translation[i]:\n",
    "                    if idx.item() == EOS_token:\n",
    "                        break\n",
    "                    translation[i][0].append(output_lang.index2word[idx.item()])\n",
    "            #print(decoded_words,\"\\n\",translation)\n",
    "            bleu_score=tm.bleu_score(decoded_words,translation,max_n = 4)\n",
    "            total_bleu_score+=bleu_score\n",
    "            #print(bleu_score)\n",
    "    \n",
    "    return total_bleu_score/len(test_dataloader) #возвращаем перевод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3882bb8-cfd5-4037-8654-06d5739f3309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9751919421348755"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_evaluate(test_dataloader,encoder, decoder,input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b8d849-9e8c-40a9-9ecd-7eb658487495",
   "metadata": {},
   "source": [
    "<h3> Исходя из оценок можно утверждать что мы добились устойчивой работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f617201b-bbd5-4b87-b51b-040f9657d213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> vous n etes pas contusionne\n",
      "= you re not bruised\n",
      "< you re not bruised <EOS>\n",
      "\n",
      "> vous etes probablement trop jeune pour le comprendre\n",
      "= you re probably too young to understand this\n",
      "< you re probably too young to understand this <EOS>\n",
      "\n",
      "> je suis ici pour requerir ton aide\n",
      "= i m here to ask for your help\n",
      "< i m here to ask for your help <EOS>\n",
      "\n",
      "> il est motive pour reussir\n",
      "= he is eager to succeed\n",
      "< he is eager to succeed <EOS>\n",
      "\n",
      "> ils ramassent des noisettes\n",
      "= they are gathering nuts\n",
      "< they are gathering nuts <EOS>\n",
      "\n",
      "> je suis sure que tout ira bien\n",
      "= i m sure everything will be fine\n",
      "< i m sure everything will be fine <EOS>\n",
      "\n",
      "> il n est pas plus fort que moi\n",
      "= he s not stronger than me\n",
      "< he s not stronger than me <EOS>\n",
      "\n",
      "> il a peur de la mer\n",
      "= he s afraid of the sea\n",
      "< he s afraid of the sea <EOS>\n",
      "\n",
      "> vous n etes pas une espionne si ?\n",
      "= you aren t a spy are you ?\n",
      "< you aren t a spy are you ? <EOS>\n",
      "\n",
      "> j ai sommeil alors je pars maintenant\n",
      "= i m sleepy so i am leaving now\n",
      "< i m sleepy so i am leaving now <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval() #переходим в ознакомительный режим\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder) # проводим оценку получившегося"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89893f70-77b3-4feb-8c79-130d31977aab",
   "metadata": {},
   "source": [
    "<h3> В целом похоже на правду. Обучение можно считать успешным"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521c440-4bf0-4cbf-a0ae-bcbfe96009ed",
   "metadata": {},
   "source": [
    "<h3> Можно визуализирвать результаты attention, чтобы просмотреть какие именно состояния выбираются attention и влияют на предсказания декодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a675d171-3131-4675-a4cd-089ec5db6f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ov00v\\AppData\\Local\\Temp\\ipykernel_4356\\2667491203.py:2: MatplotlibDeprecationWarning: Auto-close()ing of figures upon backend switching is deprecated since 3.8 and will be removed in 3.10.  To suppress this warning, explicitly call plt.close('all') first.\n",
      "  matplotlib.use('TkAgg')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = il n est pas aussi grand que son pere\n",
      "output = he s not as tall as his father <EOS>\n",
      "input = je suis trop fatigue pour conduire\n",
      "output = i m too tired to drive <EOS>\n",
      "input = je suis desole si c est une question idiote\n",
      "output = i m sorry if this is a stupid question <EOS>\n",
      "input = je suis reellement fiere de vous\n",
      "output = i m really proud of you <EOS>\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticks(range(len(input_sentence.split(' '))+2))\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticks(range(len(output_words)+1))\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
    "\n",
    "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
    "\n",
    "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
    "\n",
    "evaluateAndShowAttention('je suis reellement fiere de vous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf8e18-d8c8-4ada-90d6-e7447d6770c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde2e54-3ed1-40b7-81f5-9559500a4bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f88c0-7322-42ef-8509-c8ecfcad2cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a09900-d337-4a84-be40-469ddf814577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b27f8-ac9f-44c4-a424-70f12e1fb2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8bfd76-42fd-47c9-a3bd-2255147a7029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
